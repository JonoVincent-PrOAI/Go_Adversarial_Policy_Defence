{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "429a6053",
   "metadata": {},
   "source": [
    "## How to Train the Adversarial Detection Model\n",
    "\n",
    "### 0. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33c4cfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '../../' not in sys.path:\n",
    "    sys.path.append('../../')\n",
    "\n",
    "#Lib Imports\n",
    "import torch\n",
    "import shutil\n",
    "import os \n",
    "import engines.KataGo.python.katago.train.load_model as load_model\n",
    "import json\n",
    "import gzip\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from subprocess import Popen, PIPE, STDOUT\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Submodule Imports\n",
    "from engines.KataGo.python.katago.game.board import Board\n",
    "from engines.KataGo.python.katago.game.gamestate import GameState\n",
    "from engines.KataGo.python.katago.game.features import Features\n",
    "\n",
    "#SRC Imports\n",
    "from adv_detection.sgf_reader import SGFReader as reader\n",
    "from adv_detection.probe import Probe\n",
    "from adv_detection.adv_det_train import Training_Loop\n",
    "from adv_detection.adv_det_dataset import Adversarial_Detection_Dataset as adv_dataset\n",
    "from adv_detection.adv_det_model import Model\n",
    "from adv_detection.adv_det_eval import Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f439dc53",
   "metadata": {},
   "source": [
    "### 1. Create Dataset\n",
    "\n",
    "##### 1.1 Instance the victim model\n",
    "##### This lets us see what the available block outputs are see we can decide which ones to use to create the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "204b1863",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yz24943/Documents/Research/Summer_Project/Go_Adversarial_Policy_Defence/src/adv_detection/../../engines/KataGo/python/katago/train/load_model.py:46: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(checkpoint_file,map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rconv1.out', 'rconv2.out', 'rconv3.out', 'rconv4.out', 'rconv5.out', 'rconv6.out', 'rconv7.out', 'rconv8.out', 'rconv9.out', 'rconv10.out', 'rconv11.out', 'rconv12.out', 'rconv13.out', 'rconv14.out', 'rconv15.out', 'rconv16.out', 'rconv17.out', 'rconv18.out']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Where the file path to the victim model is set\n",
    "nn_chkpt = '../../models/kataGo/ckpt_files/kata1-b18c384nbt-s9996604416-d4316597426/model.ckpt'\n",
    "kata_model, kata_swa_model, other_state_dict = load_model.load_model(nn_chkpt, use_swa=True, device = torch.device(\"cpu\"))\n",
    "\n",
    "#This defines which conv blocks outputs are stored\n",
    "blocks = np.array(kata_model.block_kind)\n",
    "block_extra_outputs = [layer_name + '.out' for layer_name in blocks[0:,0]]\n",
    "\n",
    "print(block_extra_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c252956",
   "metadata": {},
   "source": [
    "#### 1.2 Instance the Probe and Batch the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eedff2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#File directories and setting seed\n",
    "adv_data_dir = 'detection_dataset/Game_Data/may-big-matchup/Adversarial_Policies'\n",
    "non_adv_data_dir = 'detection_dataset/Game_Data/may-big-matchup/Non-Adv_Policies'\n",
    "seed = 42\n",
    "\n",
    "#Instances the Probe\n",
    "control_probe = Probe(adv_data_dir, non_adv_data_dir, seed)\n",
    "\n",
    "#Splits the data into batches with equal split between games\n",
    "batch_size = 100\n",
    "batched_data = control_probe.equal_batch_data(batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48093d17",
   "metadata": {},
   "source": [
    "#### 1.3 Probe the Batches\n",
    "#### This Takes 30 - 40 minutes per 100 games, and can take up a lot of space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9fe040eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'detection_dataset/Probe_Data/train/may24_victim/rconv18' created successfully.\n",
      "Directory 'detection_dataset/Probe_Data/eval/may24_victim/rconv18' created successfully.\n"
     ]
    }
   ],
   "source": [
    "#Creating a separate Eval Set so That Games Do not appear in Both Sets\n",
    "train_data_dir_path = 'detection_dataset/Probe_Data/train'\n",
    "eval_data_dir_path = 'detection_dataset/Probe_Data/eval'\n",
    "\n",
    "model_name = 'may24_victim'\n",
    "#Determines which convolutional block outputs are stored in this case we are using the last layer output\n",
    "probe_layers = ['rconv18.out']\n",
    "\n",
    "train_batch_num = 0\n",
    "eval_batch_num = 1\n",
    "\n",
    "Probe.probe_batch(Probe, nn_chkpt, model_name, probe_layers, batched_data, train_batch_num, train_data_dir_path)\n",
    "Probe.probe_batch(Probe, nn_chkpt, model_name, probe_layers, batched_data, eval_batch_num, eval_data_dir_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d280639",
   "metadata": {},
   "source": [
    "#### 1.4 Have a Look at the MetaData if you Like\n",
    "#### Each directory you store a probed batch in has it's own meta_data.json file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f128b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "eval_meta_data_file = 'detection_dataset/Probe_Data/eval/may24_victim/meta_data.json'\n",
    "\n",
    "with open(eval_meta_data_file) as json_data:\n",
    "    meta_data  = json.load(json_data)\n",
    "    json_data.close()\n",
    "    print('meta_data has two keys:')\n",
    "    for key in meta_data.keys():\n",
    "        print('     ' + str(key))\n",
    "\n",
    "    print('\\nThe model data, covers the inofrmation about the model which was probed: ')\n",
    "    for key in meta_data['model data'].keys():\n",
    "        print('     ' + str(key))\n",
    "\n",
    "    print('\\nThe game data, holds information on each game in the directory: ')\n",
    "    print('It contains the nicknames of the models, the version numbers and the label')\n",
    "    for key in meta_data['game data'][42:52]:\n",
    "        print('     ' + str(key))\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2393c34c",
   "metadata": {},
   "source": [
    "### 2. Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cd2f39de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yz24943/Documents/Research/Summer_Project/Go_Adversarial_Policy_Defence/venv/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/Users/yz24943/Documents/Research/Summer_Project/Go_Adversarial_Policy_Defence/src/adv_detection/adv_det_train.py:127: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n",
      "/Users/yz24943/Documents/Research/Summer_Project/Go_Adversarial_Policy_Defence/venv/lib/python3.11/site-packages/torch/cuda/__init__.py:63: FutureWarning: The pynvml package is deprecated. Please install nvidia-ml-py instead. If you did not install pynvml directly, please report this to the maintainers of the package that installed pynvml for you.\n",
      "  import pynvml  # type: ignore[import]\n",
      "/Users/yz24943/Documents/Research/Summer_Project/Go_Adversarial_Policy_Defence/src/adv_detection/adv_det_train.py:175: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.detach().clone() or sourceTensor.detach().clone().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(labels)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.9922580645161291\n"
     ]
    }
   ],
   "source": [
    "#Train Parametres\n",
    "lr = 0.0001\n",
    "epochs = 1\n",
    "batch_size = 128\n",
    "\n",
    "train_data_dir_path = 'detection_dataset/Probe_Data/train/may24_victim/rconv18'\n",
    "eval_data_dir_path = 'detection_dataset/Probe_Data/eval/may24_victim/rconv18'\n",
    "\n",
    "#Instancing the training Loop \n",
    "train_loop = Training_Loop(train_data_dir_path, batch_size, epochs, lr)\n",
    "\n",
    "train_loop.train(epochs)\n",
    "\n",
    "#You can train using wandb to log the trianing\n",
    "#train_loop.train_and_log(epochs, 'test_run', 'API KEY')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53704ddc",
   "metadata": {},
   "source": [
    "### 3. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a7a2992c",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: b'detection_dataset/Probe_Data/eval_fixed'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../../models/detection/model_0.chkpt\u001b[39m\u001b[38;5;124m'\u001b[39m, weights_only\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28meval\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mEvaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdetection_dataset/Probe_Data/eval_fixed\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m acc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_model()\n\u001b[1;32m      7\u001b[0m pol_eval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28meval\u001b[39m\u001b[38;5;241m.\u001b[39mevaluate_per_policy()\n",
      "File \u001b[0;32m~/Documents/Research/Summer_Project/Go_Adversarial_Policy_Defence/src/adv_detection/adv_det_eval.py:28\u001b[0m, in \u001b[0;36mEvaluation.__init__\u001b[0;34m(self, model, data_path, batch_sz, num_workers)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, model, data_path, batch_sz, num_workers):\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_sz \u001b[38;5;241m=\u001b[39m batch_sz\n\u001b[0;32m---> 28\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset \u001b[38;5;241m=\u001b[39m \u001b[43madv_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataloader \u001b[38;5;241m=\u001b[39m DataLoader(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_sz, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, num_workers \u001b[38;5;241m=\u001b[39m num_workers)\n\u001b[1;32m     31\u001b[0m     meta_data_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(data_path) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/meta_data.json\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[0;32m~/Documents/Research/Summer_Project/Go_Adversarial_Policy_Defence/src/adv_detection/adv_det_dataset.py:21\u001b[0m, in \u001b[0;36mAdversarial_Detection_Dataset.__init__\u001b[0;34m(self, dir_path, file_list)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file_list \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     20\u001b[0m     data_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mfsencode(dir_path)\n\u001b[0;32m---> 21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_list \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_list \u001b[38;5;241m=\u001b[39m file_list\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: b'detection_dataset/Probe_Data/eval_fixed'"
     ]
    }
   ],
   "source": [
    "\n",
    "model = torch.load('../../models/detection/model_0.chkpt', weights_only=False)\n",
    "\n",
    "eval = Evaluation(model, 'detection_dataset/Probe_Data/eval_fixed', 10, 0)\n",
    "\n",
    "acc = eval.evaluate_model()\n",
    "\n",
    "pol_eval = eval.evaluate_per_policy()\n",
    "\n",
    "move_eval = eval.evaluate_per_move()\n",
    "\n",
    "class_eval = eval.evaluate_per_class()\n",
    "\n",
    "print('Accuracy: ' + str(acc))\n",
    "print('Positive Acc: ' + str(class_eval[1]))\n",
    "print('Negative Acc: ' + str(class_eval[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc4b0dd",
   "metadata": {},
   "source": [
    "#### 3.1 Graph Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c0a497",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'move_eval' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m colours \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#4477AA\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#66CCEE\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#228833\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#CCBB44\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#EE6677\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#AA3377\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m#BBBBBB\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 3\u001b[0m both_x, both_y \u001b[38;5;241m=\u001b[39m \u001b[43mmove_eval\u001b[49m[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys(), move_eval[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m      4\u001b[0m adv_x, adv_y \u001b[38;5;241m=\u001b[39m move_eval[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys(), move_eval[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m      5\u001b[0m non_x, non_y \u001b[38;5;241m=\u001b[39m move_eval[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mkeys(), move_eval[\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'move_eval' is not defined"
     ]
    }
   ],
   "source": [
    "colours = ['#4477AA', '#66CCEE', '#228833', '#CCBB44', '#EE6677', '#AA3377', '#BBBBBB']\n",
    "\n",
    "both_x, both_y = move_eval[0].keys(), move_eval[0].values()\n",
    "adv_x, adv_y = move_eval[1].keys(), move_eval[1].values()\n",
    "non_x, non_y = move_eval[1].keys(), move_eval[1].values()\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,9), constrained_layout=True)\n",
    "\n",
    "ax.plot(both_x, both_y, color= colours[2], linewidth=2, marker='^', markersize=5, label = 'All Games')\n",
    "ax.plot(adv_x, adv_y, color= colours[0], linewidth=2, marker='o', markersize=5, linestyle = 'dashed', label = 'Adversarial Games')\n",
    "ax.plot(non_x, non_y, color= colours[3], linewidth=2, marker='o', markersize=5, linestyle = 'dashed', label = 'Non-Adversarial Games')\n",
    "#ax.set_facecolor('#e7e7e7')\n",
    "\n",
    "ax.set_title('Classifier Accuracy Throughout Go Games', fontsize=18, pad=20)\n",
    "\n",
    "ax.legend(    \n",
    "    title='Legend',\n",
    "    title_fontsize=13,\n",
    "    fontsize=12,\n",
    "    loc='lower right',\n",
    "    frameon=True,\n",
    "    facecolor='white',\n",
    "    edgecolor='gray',\n",
    "    fancybox=True,\n",
    "    framealpha=0.9,\n",
    "    borderpad=1,\n",
    "    labelspacing=0.5\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Move Number', fontsize=14)\n",
    "ax.set_ylabel('Accuracy(%)', fontsize=14)\n",
    "ax.tick_params(axis='both', labelsize=12)\n",
    "ax.yaxis.grid(color = 'gray', linestyle = 'dashed')\n",
    "ax.tick_params(\"x\", rotation=60)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a4c969",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('detection_model_eval/R8M10-eval.json', 'r') as eval_file:\n",
    "    eval_dict = json.load(eval_file)\n",
    "    acc_move = eval_dict['acc_per_move']\n",
    "    acc_adv = eval_dict[\"acc_adv\"]\n",
    "    acc_non =  eval_dict['acc_non_adv']\n",
    "    acc_per_model = eval_dict['acc_per_adv_model']\n",
    "\n",
    "\n",
    "def make_dict_graph(acc_move, bin_size, cut_off):\n",
    "    x = []\n",
    "    y = []\n",
    "    key_list = [int(key) for key in acc_move.keys()]\n",
    "    key_list.sort()\n",
    "    for i in range(0, cut_off + bin_size, bin_size):\n",
    "        x.append(i)\n",
    "        correct = 0\n",
    "        size = 0\n",
    "        for j in range(bin_size - 1):\n",
    "            if i+j in key_list:\n",
    "                correct = correct + sum(acc_move[str(i+j)])\n",
    "                size = size + len(acc_move[str(i+j)])\n",
    "        if size !=0:\n",
    "            y.append(100* (correct/size))\n",
    "        else:\n",
    "            y.append(0)\n",
    "\n",
    "    return(x,y)\n",
    "\n",
    "colours = ['#4477AA', '#66CCEE', '#228833', '#CCBB44', '#EE6677', '#AA3377', '#BBBBBB']\n",
    "\n",
    "CUT_OFF = 350\n",
    "BIN_SIZE = 10\n",
    "\n",
    "both_x, both_y = make_dict_graph(acc_move, BIN_SIZE, CUT_OFF)\n",
    "adv_x, adv_y = make_dict_graph(acc_adv,BIN_SIZE, CUT_OFF)\n",
    "non_x, non_y = make_dict_graph(acc_non, BIN_SIZE, CUT_OFF)\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,9), constrained_layout=True)\n",
    "ax.set_xticks(both_x[::5])\n",
    "ax.plot(both_x, both_y, color= colours[2], linewidth=2, marker='^', markersize=5, label = 'All Games')\n",
    "ax.plot(adv_x, adv_y, color= colours[0], linewidth=2, marker='o', markersize=5, linestyle = 'dashed', label = 'Adversarial Games')\n",
    "ax.plot(non_x, non_y, color= colours[3], linewidth=2, marker='o', markersize=5, linestyle = 'dashed', label = 'Non-Adversarial Games')\n",
    "#ax.set_facecolor('#e7e7e7')\n",
    "\n",
    "ax.set_title('Classifier Accuracy Throughout Go Games', fontsize=18, pad=20)\n",
    "\n",
    "ax.legend(    \n",
    "    title='Legend',\n",
    "    title_fontsize=13,\n",
    "    fontsize=12,\n",
    "    loc='lower left',\n",
    "    frameon=True,\n",
    "    facecolor='white',\n",
    "    edgecolor='gray',\n",
    "    fancybox=True,\n",
    "    framealpha=0.9,\n",
    "    borderpad=1,\n",
    "    labelspacing=0.5\n",
    "    )\n",
    "\n",
    "ax.set_xlabel('Move Number', fontsize=14)\n",
    "ax.set_ylabel('Accuracy(%)', fontsize=14)\n",
    "ax.tick_params(axis='both', labelsize=12)\n",
    "ax.yaxis.grid(color = 'gray', linestyle = 'dashed')\n",
    "ax.tick_params(\"x\", rotation=60)\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
